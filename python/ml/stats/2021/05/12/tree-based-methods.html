<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Tree based methods | Fabian’s online notebook</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Tree based methods" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Online notebook for code and thoughts." />
<meta property="og:description" content="Online notebook for code and thoughts." />
<link rel="canonical" href="https://fabiangunzinger.github.io/blog/python/ml/stats/2021/05/12/tree-based-methods.html" />
<meta property="og:url" content="https://fabiangunzinger.github.io/blog/python/ml/stats/2021/05/12/tree-based-methods.html" />
<meta property="og:site_name" content="Fabian’s online notebook" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-05-12T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Online notebook for code and thoughts.","url":"https://fabiangunzinger.github.io/blog/python/ml/stats/2021/05/12/tree-based-methods.html","@type":"BlogPosting","headline":"Tree based methods","dateModified":"2021-05-12T00:00:00-05:00","datePublished":"2021-05-12T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://fabiangunzinger.github.io/blog/python/ml/stats/2021/05/12/tree-based-methods.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://fabiangunzinger.github.io/blog/feed.xml" title="Fabian's online notebook" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Fabian&#39;s online notebook</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Tree based methods</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-05-12T00:00:00-05:00" itemprop="datePublished">
        May 12, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      4 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#python">python</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#ml">ml</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#stats">stats</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          
          
          
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/3333-01-01-tree-based-methods.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Trees<ul>
<li>Are an easy and intuitive way to split data within a sample. </li>
<li>Problem, they are not good at predicting out-of-sample (with different datasets)  </li>
</ul>
</li>
<li>
<p>Random Forests </p>
<ul>
<li>Random forests remedy this by combining the simplicity of decision trees with flexibility, which leads to a large improvement in predictive accuracy. </li>
<li>How to make a random forest: <ul>
<li>Create bootstrapped sample from data (i.e. sample observations of the original sample with replacement) </li>
<li>Create a decision tree using only a subset of randomly selected variables at each step (e.g. only 2 out of 4 for root, then 2 out of remaining 3 at next node, ect.) </li>
<li>Repeat above two steps many times (e.g. 1000) to build many trees (and build a random forest) </li>
</ul>
</li>
<li>To predict outcome for new observation, do the following: <ul>
<li>Feed data into each tree in the forest and keep score of the predictions (either Yes or No for each tree). The outcome with the most scores is the prediction. </li>
</ul>
</li>
<li>The process is called “Bagging” because we Bootstrap the data and rely on the AGGregate to make a decision. </li>
<li>How can we test how good a tree is at out-of sample prediction without having another sample? <ul>
<li>Bootstrapping relies on randomly sampling from data with replacement, hence, not all observations will be used to create a tree. </li>
<li>The unused observations are called the “Out-of-bag Dataset”. We can use these test whether our Forest is any good at predicting. </li>
<li>We simply take the out-of-bag dataset from each tree, run through the entire Forest and check whether the Forest accurately classifies the observation. We then repeat this for each out-of-bag dataset. </li>
<li>The proportion of incorrectly classified out-of-bag samples is called the “out-of-bag error”. </li>
</ul>
</li>
<li>The out-of-bag error is what helps us determine how many variables to use when building our random trees above. The algorithm builds different forests with different numbers of variables (typically starting with the square-root of the total number of variables – e.g. 2 if we have 4 variables – and then calculating a few above and below that) and then picks the one with the smallest out-of-bag error.  </li>
</ul>
</li>
<li>
<p>Ada boosts </p>
<ul>
<li>When building random forests, trees vary in their depth. </li>
<li>When using Ada boost to create a Random Forest, each tree is usually just one node and two leaves. (A tree with one node and two leaves is a “stump”). So, Ada boost produces a Forest of Stumps. </li>
<li>Because a stump only makes use of a single variable, they are generally poor predictors. </li>
<li>Main ideas of ada boost <ul>
<li>Take Forest of Stumps </li>
<li>Stumps have different weights (mounts of say) in the calculation of the out-of-bag error (with the weights being proportional to the gravity of the prediction errors they make. Loosely speaking, for how many observations they get the prediction wrong).  </li>
<li>Each stump takes the errors of the previous stump into account (it does this by treating as more important those observations that the previous stump misclassified).  </li>
</ul>
</li>
<li>Process <ul>
<li>Create first Stump using the variable that best classifies outcomes </li>
<li>Then calculate classification error </li>
<li>The size of that error determines the weight this stump gets in the overall classification (i.e. in the Forest of Stumps). </li>
<li>The next stump will be build using the variable that best classifies outcomes in a dataset that over-emphasizes the observations that the previous stump misclassified. </li>
<li>As in a Random Forst, we run all obseravtions through all Stumps and keep track of the classification. Instead of adding up the Yes and No, we add up the amount of say of the Yes Stumps and No Stumps and classify as Yes if total amount of say of yes Stumps is larger. </li>
</ul>
</li>
</ul>
</li>
<li>
<p>Gradient boosting (most used configuration) </p>
<ul>
<li>Comparison to Ada boost <ul>
<li>Like Ada boost builds fixed size trees, but they can be larger than a Stump (in our specification, we use trees with a depth of 5) </li>
<li>GB also scales trees, but all by same amount </li>
<li>Also builds tree based on error of previous tree </li>
</ul>
</li>
<li>Algorithm <ul>
<li>Predict based on average and calculate (pseudo residuals) </li>
<li>Then build a tree to predict residuals </li>
<li>Scale predicted residual by the learning rate (we use 0.1) and add to original prediction. </li>
<li>Calculate new pseudo residuals and build new tree to predict. </li>
<li>Add scaled predictions to the previous prediction (i.e. to the original prediction and the previous scaled prediction). </li>
<li>Keep going like this until additional trees no longer improve prediction or hit number of max trees. </li>
</ul>
</li>
</ul>
</li>
<li>
<p>Initial prediction is log of odds: log(number in HE/number not in HE) and convert to a probability using the logistic function (e^logodds / 1 + e^logodds). If probability &gt; 0.5, prediction is “Yes” for all observations. Else is no </p>
</li>
<li>Calculate pseudo residuals as actual - predicted (e.g. 1 - 0.7) </li>
<li>Build tree to predict residuals</li>
</ul>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="fabiangunzinger/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/python/ml/stats/2021/05/12/tree-based-methods.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Online notebook for code and thoughts.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"></ul>
</div>

  </div>

</footer>
</body>

</html>
