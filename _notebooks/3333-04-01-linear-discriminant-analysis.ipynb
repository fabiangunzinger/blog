{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "\n",
    "- hide: true\n",
    "- toc: true\n",
    "- comments: true\n",
    "- categories: [ml, stats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When will KNN do poorly?\n",
    "\n",
    "- Curse of dimensionality: for a given number of observations, the nore dimensions we have in the data (the more features), the further apart obseravtions are in space, and the harder it is for KNN to do well, because while it can find \"nearest\" neighbours, these neighbours won't be very near and thus not similar and useful to predict result of new data.\n",
    "\n",
    "- In contrast, linear regression is robust because it uses all points to calculate fitted line/plane, and is not affected by \"gaps\" in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "- [The hundred-page machine learning book](http://themlbook.com)\n",
    "- [An introduction to statistical learning](https://www.statlearning.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habits",
   "language": "python",
   "name": "habits"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
