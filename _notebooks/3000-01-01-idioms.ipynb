{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python data science idioms\n",
    "\n",
    "- hide: true\n",
    "- sticky_rank: 1\n",
    "- toc: true\n",
    "- comments: true\n",
    "- categories: [python]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A repository for best practice solutions to things I find myself doing over and over again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nspl_aug_2020_uk.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "'NSPL_AUG_2020_UK.csv'.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data sciencebasename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing pipeline\n",
    "\n",
    "Each dataset is unique, but the steps to clean it are not. Here I document a series steps I use to clean each and ensure the quality of each dataset I work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data (from disk or s3)\n",
    "# clean (standardise varnames, drop unneeded vars, etc.)\n",
    "# reshape\n",
    "# ...\n",
    "# test\n",
    "# write to disk or s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorder dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = ['date', 'yw', 'pcsector']\n",
    "rest = set(df.columns) - set(first)\n",
    "df = df[first + list(rest)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a subset of users from a panel dataset based on user-level criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I have a folder of files which I want to clean and append. How to do this?\n",
    "- I want to convert a df column to datatime, how to do this (at read, using np, using Pandas)? What are tradeoffs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing command line arguments\n",
    "\n",
    "Rationale:\n",
    "\n",
    "- Ensures that `sys.argv`, which is not immutable, doesn't get altered between command invocation and execution of `main`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "\n",
    "def parse_args(argv):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('argname')\n",
    "    parser.add_argument('--test', action='store_true',\n",
    "                        help='Read subset of files only.')\n",
    "    parser.add_argument('--nrows', type=int,\n",
    "                        help='Number of rows to read per file.')\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def main(args=None):\n",
    "    if args is None:\n",
    "        args = sys.argv[1:]\n",
    "    print(f'argname is {args.argname}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `ast.literal_eval() ` instead of `eval()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, because `eval` is very [dangerous](https://nedbatchelder.com/blog/201206/eval_really_is_dangerous.html) and would happile evaluate a string like `os.system(rm -rf /)`, while `ast.literal_eval` will only evaluate Python [literals](https://docs.python.org/3/library/ast.html#ast.literal_eval)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "- [Fluent Python](https://www.oreilly.com/library/view/fluent-python/9781491946237/)\n",
    "- [Python Cookbook](https://www.oreilly.com/library/view/python-cookbook-3rd/9781449357337/)\n",
    "- [Learning Python](https://www.oreilly.com/library/view/learning-python-5th/9781449355722/)\n",
    "- [The Hitchhiker's Guide to Python](https://docs.python-guide.org/writing/structure/)\n",
    "- [Effective Python](https://effectivepython.com)\n",
    "- [Python for Data Analysis](https://www.oreilly.com/library/view/python-for-data/9781491957653/)\n",
    "- [Python Data Science Handbook](https://www.oreilly.com/library/view/python-data-science/9781491912126/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habits",
   "language": "python",
   "name": "habits"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
